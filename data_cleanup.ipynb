{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1-Lher_lUMqby9LOGtRoczaQp7c3wI7Tk","authorship_tag":"ABX9TyNuwokZwXsSfv2ZNmkbRr4t"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install jsonlines"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q9_Ad_fb8ZQU","executionInfo":{"status":"ok","timestamp":1734093481288,"user_tz":180,"elapsed":4147,"user":{"displayName":"João Gabriel","userId":"02887411909052297991"}},"outputId":"a4f27653-a573-4f93-8356-4af5eba6faff"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: jsonlines in /usr/local/lib/python3.10/dist-packages (4.0.0)\n","Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines) (24.2.0)\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"l0t91yL-5jNk","executionInfo":{"status":"ok","timestamp":1734093485525,"user_tz":180,"elapsed":1456,"user":{"displayName":"João Gabriel","userId":"02887411909052297991"}}},"outputs":[],"source":["import os\n","import jsonlines\n","import random\n","import pandas as pd\n","from typing import List\n","from typing import Tuple\n","import pandas as pd"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QnikIXgX8b_H","executionInfo":{"status":"ok","timestamp":1734093488500,"user_tz":180,"elapsed":1710,"user":{"displayName":"João Gabriel","userId":"02887411909052297991"}},"outputId":"fb282a5e-33c9-4d57-951b-90bb2bcfbb7e"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["file_path = '/content/drive/MyDrive/Colab Notebooks/dataset/trn.json'\n","\n","df = pd.read_json(file_path, lines=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":321},"id":"dn-R2K018dVN","executionInfo":{"status":"error","timestamp":1734093501141,"user_tz":180,"elapsed":10196,"user":{"displayName":"João Gabriel","userId":"02887411909052297991"}},"outputId":"eba13833-0d25-425f-fa16-28dd22b0905d"},"execution_count":4,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-becf21f0a32a>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/Colab Notebooks/dataset/trn.json'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options, dtype_backend, engine)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0mconvert_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m     json_reader = JsonReader(\n\u001b[0m\u001b[1;32m    792\u001b[0m         \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m         \u001b[0morient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morient\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, lines, chunksize, compression, nrows, storage_options, encoding_errors, dtype_backend, engine)\u001b[0m\n\u001b[1;32m    903\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"ujson\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data_from_filepath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 905\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_preprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m_preprocess_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    915\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStringIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["num_rows, num_columns = df.shape\n","print(f\"Total de linhas: {num_rows}\")\n","print(f\"Total de colunas: {num_columns}\")"],"metadata":{"id":"TOkD6gL7-EvS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"\\nPrimeiras linhas do dataset:\")\n","print(df.head())"],"metadata":{"id":"8dtARWD6-KJw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def load_dataset(input_file: str) -> List[dict]:\n","    \"\"\"\n","    Carrega o dataset a partir de um arquivo JSONLines.\n","\n","    Args:\n","        input_file (str): Caminho do arquivo JSONLines de entrada.\n","\n","    Returns:\n","        List[dict]: Lista de dicionários com os dados do JSONLines.\n","    \"\"\"\n","    try:\n","        with jsonlines.open(input_file, mode='r') as reader:\n","            return [line for line in reader]\n","    except Exception as e:\n","        raise ValueError(f\"Erro ao carregar o arquivo: {e}\")\n","\n","def validate_inputs(input_file: str, fraction: float) -> None:\n","    \"\"\"\n","    Valida os inputs para a função create_sample_dataset.\n","    \"\"\"\n","    if not os.path.exists(input_file):\n","        raise FileNotFoundError(f\"O arquivo {input_file} não foi encontrado.\")\n","    if not (0 < fraction <= 1):\n","        raise ValueError(\"A fração deve estar no intervalo (0, 1].\")"],"metadata":{"id":"RFcFHr-m-Lxe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def filter_empty_entries(data: pd.DataFrame) -> pd.DataFrame:\n","    \"\"\"\n","    Remove entradas vazias do DataFrame.\n","\n","    Args:\n","        data (pd.DataFrame): DataFrame contendo as colunas 'title' e 'content'.\n","\n","    Returns:\n","        pd.DataFrame: DataFrame filtrado sem entradas vazias.\n","    \"\"\"\n","    print(f\"Linhas antes da filtragem: {len(data)}\")\n","    filtered_data = data.dropna(subset=['title', 'content']).query(\"title != '' and content != ''\")\n","    print(f\"Linhas após a filtragem: {len(filtered_data)}\")\n","    return filtered_data"],"metadata":{"id":"wFF8W9ck-YF0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_sample_dataset(input_file: str, output_file: str, fraction: float, seed: int) -> Tuple[int, int]:\n","    \"\"\"\n","    Extrai uma fração aleatória do dataset, mantém 'title' e 'content',\n","    remove entradas vazias e salva em um novo arquivo.\n","\n","    Args:\n","        input_file (str): Caminho do arquivo JSONLines de entrada.\n","        output_file (str): Caminho do arquivo JSONLines de saída.\n","        fraction (float): Fração do dataset a ser extraída.\n","        seed (int): Semente para garantir reprodutibilidade.\n","\n","    Returns:\n","        Tuple[int, int]: Total de linhas no dataset final e total de registros originais.\n","    \"\"\"\n","    try:\n","        # Validar entradas\n","        validate_inputs(input_file, fraction)\n","\n","        # Carregar o dataset\n","        print(\"Carregando o dataset...\")\n","        data = load_dataset(input_file)\n","\n","        if not data:\n","            print(\"O arquivo de entrada está vazio.\")\n","            return 0, 0\n","\n","        # Configurar a semente para seleção reprodutível\n","        random.seed(seed)\n","\n","        # Selecionar amostra\n","        total_samples = len(data)\n","        num_samples = max(1, int(total_samples * fraction))\n","        print(f\"Total de registros no arquivo original: {total_samples}\")\n","        print(f\"Número de registros selecionados: {num_samples}\")\n","        sampled_data = random.sample(data, num_samples)\n","\n","        # Processar dados\n","        print(\"Processando os dados...\")\n","        processed_data = [\n","            {\"title\": entry.get(\"title\", \"\"), \"content\": entry.get(\"content\", \"\")}\n","            for entry in sampled_data\n","        ]\n","\n","        # Converter para DataFrame\n","        df = pd.DataFrame(processed_data)\n","\n","        # Filtrar entradas vazias\n","        df = filter_empty_entries(df)\n","\n","        # Salvar o dataset tratado\n","        print(f\"Salvando o dataset em {output_file}...\")\n","        df.to_json(output_file, orient=\"records\", lines=True, force_ascii=False)\n","        print(f\"Dataset tratado salvo com sucesso em: {output_file}\")\n","\n","        # Retornar a contagem final de linhas\n","        total_final = len(df)\n","        return total_final, total_samples\n","\n","    except Exception as e:\n","        print(f\"Erro durante o processamento: {e}\", exc_info=True)\n","        return 0, 0"],"metadata":{"id":"WFnPHKGb-b68"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def analyze_dataset(file_path: str) -> None:\n","    \"\"\"\n","    Analisa um arquivo JSONLines para verificar se todas as linhas seguem o formato esperado.\n","\n","    Args:\n","        file_path (str): Caminho para o arquivo JSONLines.\n","    \"\"\"\n","    total_lines = 0\n","    valid_lines = 0\n","    missing_title = 0\n","    missing_content = 0\n","    empty_title = 0\n","    empty_content = 0\n","\n","    try:\n","        print(f\"Analisando o arquivo: {file_path}\")\n","        with jsonlines.open(file_path, mode='r') as reader:\n","            for line in reader:\n","                total_lines += 1\n","\n","                # Verificar se as chaves existem\n","                has_title = \"title\" in line\n","                has_content = \"content\" in line\n","\n","                if has_title and has_content:\n","                    # Contar como válido somente se ambas as chaves existirem\n","                    valid_lines += 1\n","\n","                    # Verificar se os valores não estão vazios\n","                    if not line[\"title\"].strip():\n","                        empty_title += 1\n","                    if not line[\"content\"].strip():\n","                        empty_content += 1\n","                else:\n","                    # Contar erros de ausência de campos\n","                    if not has_title:\n","                        missing_title += 1\n","                    if not has_content:\n","                        missing_content += 1\n","\n","        # Exibir resumo\n","        print(\"Resumo da análise do dataset:\")\n","        print(f\"Total de linhas: {total_lines}\")\n","        print(f\"Linhas válidas: {valid_lines}\")\n","        print(f\"Linhas com 'title' ausente: {missing_title}\")\n","        print(f\"Linhas com 'content' ausente: {missing_content}\")\n","        print(f\"Linhas com 'title' vazio: {empty_title}\")\n","        print(f\"Linhas com 'content' vazio: {empty_content}\")\n","        print(f\"Linhas inválidas: {total_lines - valid_lines}\")\n","\n","    except Exception as e:\n","        print(f\"Erro ao analisar o dataset: {e}\", exc_info=True)"],"metadata":{"id":"grxDeHT0-e_Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_file = \"TechChallenge-Fase3/LF-Amazon/trn-folder/trn.json\"\n","output_file = \"TechChallenge-Fase3/LF-Amazon/trn-folder/trn_tratado.json\"\n","fraction = 0.4\n","seed = 42"],"metadata":{"id":"t58Z-NtV-z2b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["analyze_dataset(input_file)"],"metadata":{"id":"5GgDADjv-3C7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Iniciando o processamento do dataset...\")\n","total_final, total_original = create_sample_dataset(input_file, output_file, fraction, seed)\n","\n","if total_original > 0:\n","    final_percentage = (total_final / total_original) * 100\n","    print(\n","        f\"Processamento concluído. Total de registros no dataset final: {total_final} \"\n","        f\"({final_percentage:.2f}% do total original).\"\n","    )\n","else:\n","    print(\"O dataset original estava vazio ou houve um erro no processamento.\")\n","\n","analyze_dataset(output_file)"],"metadata":{"id":"f35861Ic-hg_"},"execution_count":null,"outputs":[]}]}