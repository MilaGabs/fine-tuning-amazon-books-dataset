{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 222535,
     "status": "ok",
     "timestamp": 1734115712480,
     "user": {
      "displayName": "João Gabriel",
      "userId": "02887411909052297991"
     },
     "user_tz": 180
    },
    "id": "49dLl9SWLcnx"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install unsloth \"xformers==0.0.28.post2\"\n",
    "!pip uninstall unsloth -y && pip install --upgrade --no-cache-dir \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 21890,
     "status": "ok",
     "timestamp": 1734115734367,
     "user": {
      "displayName": "João Gabriel",
      "userId": "02887411909052297991"
     },
     "user_tz": 180
    },
    "id": "oN1X1aAMLk5O"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install datasets\n",
    "!pip install trl\n",
    "!pip install transformers\n",
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22010,
     "status": "ok",
     "timestamp": 1734115756368,
     "user": {
      "displayName": "João Gabriel",
      "userId": "02887411909052297991"
     },
     "user_tz": 180
    },
    "id": "i_CDNPo7Ly-T",
    "outputId": "99425d6d-90fe-47be-b6b8-c31162f02bfa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 227,
     "status": "ok",
     "timestamp": 1734116979846,
     "user": {
      "displayName": "João Gabriel",
      "userId": "02887411909052297991"
     },
     "user_tz": 180
    },
    "id": "LbT_rNC8LsJf"
   },
   "outputs": [],
   "source": [
    "from unsloth import FastLanguageModel, is_bfloat16_supported\n",
    "import torch\n",
    "import json\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "\n",
    "max_seq_length = 2048\n",
    "dtype = None\n",
    "load_in_4bit = True\n",
    "model_path = \"/content/drive/MyDrive/Colab Notebooks/unsloth_model\"\n",
    "\n",
    "fourbit_models = [\n",
    "     \"unsloth/llama-3-8b-bnb-4bit\"\n",
    "]\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42891,
     "status": "ok",
     "timestamp": 1734117026106,
     "user": {
      "displayName": "João Gabriel",
      "userId": "02887411909052297991"
     },
     "user_tz": 180
    },
    "id": "X9Tc-eGLMBHO",
    "outputId": "eaf04feb-d5c4-4b65-ceeb-8432faa13e66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2024.12.4: Fast Llama patching. Transformers:4.46.3.\n",
      "   \\\\   /|    GPU: Tesla T4. Max memory: 14.748 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.5.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.1.0\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post2. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1734117026107,
     "user": {
      "displayName": "João Gabriel",
      "userId": "02887411909052297991"
     },
     "user_tz": 180
    },
    "id": "YiPYZP8xTm_j"
   },
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    inputs = tokenizer(\n",
    "        examples['text'],\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=max_seq_length\n",
    "    )\n",
    "\n",
    "    inputs['labels'] = inputs['input_ids'].copy()\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 1130,
     "status": "ok",
     "timestamp": 1734117040663,
     "user": {
      "displayName": "João Gabriel",
      "userId": "02887411909052297991"
     },
     "user_tz": 180
    },
    "id": "BS1fUFpyMM5Q"
   },
   "outputs": [],
   "source": [
    "VALIDATION_PATH_DATASET = \"/content/drive/MyDrive/Colab Notebooks/dataset/validation_dataset\"\n",
    "\n",
    "validation_dataset = load_from_disk(VALIDATION_PATH_DATASET)\n",
    "\n",
    "validation_dataset = validation_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1734117114924,
     "user": {
      "displayName": "João Gabriel",
      "userId": "02887411909052297991"
     },
     "user_tz": 180
    },
    "id": "Gil7iWLEMhUL",
    "outputId": "4390e0e4-75ce-4e95-a797-fa36ee37f22d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-ed2cb2be2d27>:42: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = validation_dataset,\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dataset_num_proc = 2,\n",
    "    packing = False,\n",
    "    args = TrainingArguments(\n",
    "        per_device_train_batch_size = 2,\n",
    "        gradient_accumulation_steps = 4,\n",
    "        warmup_steps = 5,\n",
    "        max_steps = 1000,\n",
    "        learning_rate = 2e-4,\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs\",\n",
    "        remove_unused_columns=False\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 242,
     "status": "ok",
     "timestamp": 1734117123355,
     "user": {
      "displayName": "João Gabriel",
      "userId": "02887411909052297991"
     },
     "user_tz": 180
    },
    "id": "ZgIyD02DLpx3"
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "def calculate_perplexity(trainer, eval_dataset):\n",
    "    trainer.args.per_device_eval_batch_size = 1\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    eval_results = trainer.predict(eval_dataset)\n",
    "    perplexity = torch.exp(torch.tensor(eval_results.metrics[\"eval_loss\"]))\n",
    "    return perplexity.item()\n",
    "\n",
    "def calculate_bleu(trainer, eval_dataset):\n",
    "    trainer.args.per_device_eval_batch_size = 1\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    bleu = evaluate.load(\"bleu\")\n",
    "    predictions = trainer.predict(eval_dataset).predictions\n",
    "    decoded_preds = trainer.tokenizer.batch_decode(predictions.argmax(-1), skip_special_tokens=True)\n",
    "    decoded_labels = eval_dataset[\"output\"]\n",
    "    results = bleu.compute(predictions=decoded_preds, references=[[label] for label in decoded_labels])\n",
    "    return results[\"bleu\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426
    },
    "executionInfo": {
     "elapsed": 275,
     "status": "error",
     "timestamp": 1734117125274,
     "user": {
      "displayName": "João Gabriel",
      "userId": "02887411909052297991"
     },
     "user_tz": 180
    },
    "id": "ye6OSg5DM67C",
    "outputId": "f47aa41d-fabd-44c5-ccc9-f61df2059e59"
   },
   "outputs": [],
   "source": [
    "perplexity = calculate_perplexity(trainer, validation_dataset)\n",
    "print(f\"Perplexidade: {perplexity}\")\n",
    "\n",
    "bleu_score = calculate_bleu(trainer, validation_dataset)\n",
    "print(f\"BLEU: {bleu_score}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNCFtYFAl9wwlsM8sgES9TX",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
